# App architecture
At this point app is a very simple set of scripts. All the magic is happening in `note_app.py`. This script has functions for main features:

  * `add` to add new note. New notes are processed with an LLM to try to convert it to more general note. For example, if the note was given in imperative case ("remind me/write down/etc."), LLM is asked to process this note to be a simple clause. Also if there are dates or time reference, LLM is asked to convert those to precise dates, given today's date and day of the week. Also, LLM is asked to assign some tags automatically, so it would be possible to search by tags later.
  * `search` is used to search across all the notes using natural language. It is done by using sentence embeddings of `sentence-transformers/all-mpnet-base-v2`. The sentence embedding is applied to concatenation of current date, original message, LLM processed message and LLM automatic tags. Also search can be done with the use of LLM. To be honest, I personally prefer approach with sentence embeddings, because it is done once and it's much cheaper then LLM, and you don't have to worry about context length. Though it is possible to unite these approaches in RAG-style approach, where you first select candidates with sentence embedding, and then do precise search with an LLM. Also, it can be a separate feature, where you can have a "chat" with your notes. 
  * `show` simply shows you n messages sorted by date.
  * `clear-all` removes folder with notes. It is not a proper deletion method, it simply removes folder with notes (which is by default `~/notes_storage`)

Notes are saved in a very simple structure. Each note is saved in `json` file with fields `creation_date`, `initial_message`, `processed_message`, `tags`. 
Also the name of each `json` is it's creation date. It allows to easily sort notes by date and it is possible to use index of the note as its id. It also easy to look at what results the program got. Proper database would be more robust, but also more complex. 

# Libraries
The main libraries used are:
  * [ollama](https://github.com/ollama/ollama) - for running open sourced LLMs locally. I used `llama3 8B` model. It might be worse than using OpenAI's or Anthropic's API, but to me the possibility to run things locally is always a plus. The model type can be changed in `config.json`. One of the disadvantages is that it is distributed as a binary files and models are quite heavy (`llama3 8B` is more that 4Gbs)
  * [litellm](https://github.com/BerriAI/litellm) - for calling `ollama`. This library provides a unified interface for a lot of different APIs and for `ollama` local models, which would allow to easily switch LLM provider in the future. Also, [Open Interpreter](https://github.com/OpenInterpreter/open-interpreter) uses `litellm` under the hood and allows to run code, generated by LLM. While I didn't use open interpreter here, it could be a good extension of this app (to set reminders at the very least)
  * [sentence-transformers](https://www.sbert.net/) - for embedding notes with `all-mpnet-base-v2` for semantic search
  * [faiss](https://github.com/facebookresearch/faiss) for searching across sentence embeddings. I used simple index, but there are different kind of them, for faster search at scale. Even better option would be to use a proper database. From what I researched, [Milvus](https://milvus.io/) is a very good option for such tasks. Another good option would be `ElasticSearch`. I decided to stick with `faiss` for simplicity.
  * [click](https://github.com/pallets/click) for simple command line interface

  # Usage

 1. Installing `ollama` (not handled by pip) or changing LLM provider in `config.json`
 2. Installing package `pip install .` or `pip install -e .` for editable install. The later will allow changing LLMs later more easily
 3. You can run `bash note_generation.sh`, it contains notes that ChatGPT generated.
 
 ...
